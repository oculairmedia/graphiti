# =============================================================================
# Docker Compose Production Override
# =============================================================================
# Use this file for production deployments with optimized configurations.
# Usage: docker-compose -f docker-compose.base.yml -f docker-compose.prod.override.yml up

services:
  # =============================================================================
  # Production Message Queue
  # =============================================================================
  queued:
    image: ghcr.io/oculairmedia/graphiti-queued:latest
    container_name: graphiti-queued
    restart: unless-stopped
    ports:
      - "${QUEUE_PORT:-8093}:8080"
    volumes:
      - queued_data:/data
    environment:
      - QUEUED_DATA_DIR=/data
      - QUEUED_BIND_ADDR=0.0.0.0:8080
      - RUST_LOG=queued=info
    networks:
      - graphiti_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/queues"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1'
    labels:
      - homepage.group=Knowledge Management
      - homepage.name=Message Queue
      - homepage.icon=si-rabbitmq
      - homepage.href=http://${HOMEPAGE_HOST:-192.168.50.90}:${QUEUE_PORT:-8093}
      - homepage.description=High-performance message queue

  # =============================================================================
  # Production Worker Services
  # =============================================================================
  graphiti-worker:
    image: ghcr.io/oculairmedia/graphiti-worker:latest
    restart: unless-stopped
    environment:
      - QUEUED_URL=http://queued:8080
      - FALKORDB_HOST=${FALKORDB_HOST:-falkordb}
      - FALKORDB_PORT=${FALKORDB_PORT:-6379}
      - FALKORDB_DATABASE=${FALKORDB_DATABASE:-graphiti_migration}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - USE_CEREBRAS=${USE_CEREBRAS:-false}
      - CEREBRAS_API_KEY=${CEREBRAS_API_KEY}
      - CEREBRAS_MODEL=${CEREBRAS_MODEL:-qwen-3-coder-480b}
      - CEREBRAS_SMALL_MODEL=${CEREBRAS_SMALL_MODEL:-qwen-3-coder-480b}
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://${OLLAMA_EXTERNAL_HOST:-100.81.139.20}:11434/v1}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gemma3:12b}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-mxbai-embed-large:latest}
      - USE_OLLAMA_EMBEDDINGS=${USE_OLLAMA_EMBEDDINGS:-true}
      - WORKER_COUNT=${WORKER_COUNT:-4}
      - BATCH_SIZE=${BATCH_SIZE:-10}
      - POLL_INTERVAL=${POLL_INTERVAL:-1.0}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - graphiti_network
    depends_on:
      queued:
        condition: service_healthy
      falkordb:
        condition: service_healthy
    deploy:
      replicas: ${WORKER_REPLICAS:-2}
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 1G
          cpus: '1'
    labels:
      - homepage.group=Knowledge Management
      - homepage.name=Worker Service
      - homepage.icon=si-kubernetes
      - homepage.description=Production queue workers

  # =============================================================================
  # Production API Server
  # =============================================================================
  graphiti-api:
    image: ghcr.io/oculairmedia/graphiti-api:latest
    container_name: graphiti-api
    restart: unless-stopped
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      - QUEUED_URL=http://queued:8080
      - FALKORDB_HOST=${FALKORDB_HOST:-falkordb}
      - FALKORDB_PORT=${FALKORDB_PORT:-6379}
      - FALKORDB_DATABASE=${FALKORDB_DATABASE:-graphiti_migration}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - USE_CEREBRAS=${USE_CEREBRAS:-false}
      - CEREBRAS_API_KEY=${CEREBRAS_API_KEY}
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://${OLLAMA_EXTERNAL_HOST:-100.81.139.20}:11434/v1}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gemma3:12b}
      - USE_QUEUE_FOR_INGESTION=${USE_QUEUE_FOR_INGESTION:-true}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - NODE_ENV=production
    networks:
      - graphiti_network
    depends_on:
      falkordb:
        condition: service_healthy
      queued:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 1G
          cpus: '1'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - homepage.group=Knowledge Management
      - homepage.name=Graphiti API
      - homepage.icon=si-fastapi
      - homepage.href=http://${HOMEPAGE_HOST:-192.168.50.90}:${API_PORT:-8000}
      - homepage.description=Production API server

  # =============================================================================
  # Production Dashboard
  # =============================================================================
  graphiti-dashboard:
    image: ghcr.io/oculairmedia/graphiti-dashboard:latest
    container_name: graphiti-dashboard
    restart: unless-stopped
    ports:
      - "${DASHBOARD_PORT:-8091}:8091"
    environment:
      - QUEUED_URL=http://queued:8080
      - FALKORDB_HOST=${FALKORDB_HOST:-falkordb}
      - FALKORDB_PORT=${FALKORDB_PORT:-6379}
      - FALKORDB_DATABASE=${FALKORDB_DATABASE:-graphiti_migration}
      - DASHBOARD_PORT=8091
      - ENABLE_DASHBOARD=true
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - graphiti_network
    depends_on:
      queued:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    labels:
      - homepage.group=Knowledge Management
      - homepage.name=Queue Dashboard
      - homepage.icon=si-grafana
      - homepage.href=http://${HOMEPAGE_HOST:-192.168.50.90}:${DASHBOARD_PORT:-8091}
      - homepage.description=Queue monitoring dashboard

  # =============================================================================
  # Production Frontend
  # =============================================================================
  frontend:
    image: ghcr.io/oculairmedia/graphiti-frontend:latest
    container_name: graphiti-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-8088}:80"
    environment:
      - NODE_ENV=production
      - VITE_API_BASE_URL=http://graph-visualizer-rust:3000
      - VITE_WS_URL=ws://graph-visualizer-rust:3000/ws
    networks:
      - graphiti_network
    depends_on:
      - graph-visualizer-rust
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    labels:
      - homepage.group=Knowledge Management
      - homepage.name=Frontend
      - homepage.icon=si-react
      - homepage.href=http://${HOMEPAGE_HOST:-192.168.50.90}:${FRONTEND_PORT:-8088}
      - homepage.description=Production React frontend

  # =============================================================================
  # Production Proxy
  # =============================================================================
  nginx-proxy:
    image: nginx:alpine
    container_name: graphiti-nginx-proxy
    restart: unless-stopped
    ports:
      - "${PROXY_HTTP_PORT:-80}:80"
      - "${PROXY_HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    networks:
      - graphiti_network
    depends_on:
      - frontend
      - graphiti-api
    profiles:
      - proxy
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    labels:
      - homepage.group=Knowledge Management
      - homepage.name=Nginx Proxy
      - homepage.icon=si-nginx
      - homepage.href=http://${HOMEPAGE_HOST:-192.168.50.90}:${PROXY_HTTP_PORT:-80}
      - homepage.description=Reverse proxy for production

  # Override base services for production optimization
  falkordb:
    command:
      - falkordb-server
      - --save
      - "60"
      - "1"
      - --save
      - "300"
      - "10"
      - --save
      - "900"
      - "100"
      - --appendonly
      - "yes"
      - --appendfsync
      - "everysec"
      - --loglevel
      - "notice"
      - --maxmemory
      - "2g"
      - --maxmemory-policy
      - "allkeys-lru"
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'

  redis:
    command: ["redis-server", "--appendonly", "yes", "--appendfsync", "everysec", "--maxmemory", "1g", "--maxmemory-policy", "allkeys-lru"]
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: '1'
        reservations:
          memory: 1G
          cpus: '0.5'

volumes:
  queued_data:
    driver: local
    labels:
      - description=Message queue persistent data
  nginx_logs:
    driver: local
    labels:
      - description=Nginx access and error logs